#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
–°–∏—Å—Ç–µ–º–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤—Ö–æ–¥—è—â–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏, —Å–æ–∑–¥–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏ 
–Ω–∞—Ö–æ–¥–∏—Ç –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏–µ —à–∞–±–ª–æ–Ω—ã –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.
"""

import argparse
import json
import os
import sys
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
import numpy as np

# –ò–º–ø–æ—Ä—Ç –º–æ–¥—É–ª–µ–π –ø—Ä–æ–µ–∫—Ç–∞
from modules.parsers import parse_file_to_elements
from modules.embeddings import EmbeddingBackend, EmbeddingConfig
from modules.fast_adaptive_chunker import chunk_elements, ChunkingStats
from modules.db import DB
from modules.extractor_names import extract_title_universal

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def classify_document(
    emb_backend: EmbeddingBackend,
    db: DB,
    document_text: str,
    title_text: str = None,
    document_weight: float = 0.9,
    title_weight: float = 0.1
) -> Tuple[Optional[str], Optional[float], Optional[Dict[str, float]]]:
    """
    –£–ª—É—á—à–µ–Ω–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ —ç–º–±–µ–¥–¥–∏–Ω–≥—É –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –Ω–∞–∑–≤–∞–Ω–∏—è.
    –í—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏–π —à–∞–±–ª–æ–Ω —Å —Ä–µ–∞–ª—å–Ω—ã–º –ø—Ä–æ—Ü–µ–Ω—Ç–æ–º —Å—Ö–æ–∂–µ—Å—Ç–∏.

    Args:
        emb_backend: –±—ç–∫–µ–Ω–¥ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        db: –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
        document_text: –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞
        title_text: –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        document_weight: –≤–µ—Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.7)
        title_weight: –≤–µ—Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –Ω–∞–∑–≤–∞–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.3)

    Returns:
        Tuple[template_id, similarity_score, detailed_scores]: ID –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–µ–≥–æ —à–∞–±–ª–æ–Ω–∞, –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∫–æ—Ä –∏ –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Å–∫–æ—Ä—ã
    """
    # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞
    document_embedding = emb_backend.encode([document_text])[0]

    # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –Ω–∞–∑–≤–∞–Ω–∏—è, –µ—Å–ª–∏ –µ—Å—Ç—å
    title_embedding = None
    if title_text and title_text.strip():
        title_embedding = emb_backend.encode([title_text])[0]

    # –ò—â–µ–º –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏–π —à–∞–±–ª–æ–Ω –±–µ–∑ –ø–æ—Ä–æ–≥–∞ –æ—Ç—Å–µ—á–µ–Ω–∏—è
    similar_docs = db.find_similar_documents_enhanced(
        document_embedding,
        title_embedding=title_embedding,
        limit=1,
        threshold=0.0,  # –£–±–∏—Ä–∞–µ–º –ø–æ—Ä–æ–≥ –æ—Ç—Å–µ—á–µ–Ω–∏—è
        document_weight=document_weight,
        title_weight=title_weight
    )

    if similar_docs:
        best_match = similar_docs[0]
        detailed_scores = {
            "doc_similarity": best_match["doc_similarity"],
            "title_similarity": best_match["title_similarity"],
            "combined_similarity": best_match["combined_similarity"]
        }
        return best_match["template_id"], best_match["combined_similarity"], detailed_scores

    return None, None, None


def main():
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤—Ö–æ–¥—è—â–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
    """
    parser = argparse.ArgumentParser(
        description="–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –≤—Ö–æ–¥—è—â–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ –ø–æ—Ö–æ–∂–µ—Å—Ç–∏ —Å —à–∞–±–ª–æ–Ω–∞–º–∏"
    )
    parser.add_argument(
        "--input-dir",
        required=True,
        help="–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –≤—Ö–æ–¥—è—â–∏–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"
    )
    parser.add_argument(
        "--sbert-path",
        default=str(Path(__file__).parent / "models" / "sbert_large_nlu_ru"),
        help="–ü—É—Ç—å –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ SBERT"
    )
    parser.add_argument(
        "--similar_id",
        type=float,
        default=0.84,
        help="–ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 84%)"
    )
    parser.add_argument(
        "--embedding-dim",
        type=int,
        default=1024,
        help="–¶–µ–ª–µ–≤–∞—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"
    )
    parser.add_argument(
        "--chunk-size",
        type=int,
        default=350,
        help="–¶–µ–ª–µ–≤–æ–π —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –≤ —Ç–æ–∫–µ–Ω–∞—Ö"
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=32,
        help="–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"
    )
    parser.add_argument(
        "--device",
        default="cpu",
        choices=["cpu", "cuda", "mps"],
        help="–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π"
    )
    parser.add_argument(
        "--use-db",
        action="store_true",
        help="–°–æ—Ö—Ä–∞–Ω—è—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ PostgreSQL –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"
    )
    parser.add_argument(
        "--file-formats",
        nargs="+",
        default=[".txt", ".pdf", ".docx"],
        help="–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã —Ñ–∞–π–ª–æ–≤"
    )
    parser.add_argument(
        "--session-id",
        default="default",
        help="–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å–µ—Å—Å–∏–∏ –¥–ª—è –∏–∑–æ–ª—è—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π"
    )
    parser.add_argument(
        "--document-weight",
        type=float,
        default=0.7,
        help="–í–µ—Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø—Ä–∏ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.7)"
    )
    parser.add_argument(
        "--title-weight",
        type=float,
        default=0.3,
        help="–í–µ—Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–∏ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.3)"
    )

    args = parser.parse_args()

    logger.info("–ó–ê–ü–£–°–ö –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò –í–•–û–î–Ø–©–ò–• –î–û–ö–£–ú–ï–ù–¢–û–í")
    logger.info("=" * 60)
    logger.info(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –≤—Ö–æ–¥—è—â–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {args.input_dir}")
    logger.info(f"–ú–æ–¥–µ–ª—å SBERT: {args.sbert_path}")
    logger.info(f"–†–µ–∂–∏–º: –ø–æ–∏—Å–∫ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–µ–≥–æ —à–∞–±–ª–æ–Ω–∞ (–±–µ–∑ –ø–æ—Ä–æ–≥–∞ –æ—Ç—Å–µ—á–µ–Ω–∏—è)")
    logger.info(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {args.embedding_dim}")
    logger.info(f"–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ë–î: {args.use_db}")
    logger.info(f"ID —Å–µ—Å—Å–∏–∏: {args.session_id}")
    logger.info(
        f"–í–µ—Å–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ - –¥–æ–∫—É–º–µ–Ω—Ç: {args.document_weight:.1f}, –Ω–∞–∑–≤–∞–Ω–∏–µ: {args.title_weight:.1f}")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    input_dir = Path(args.input_dir)
    if not input_dir.exists():
        logger.error(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {input_dir}")
        sys.exit(1)

    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ —á–∞–Ω–∫–∏–Ω–≥–∞
    cfg = EmbeddingConfig(
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
        local_sbert_path=args.sbert_path,
        device=args.device,
        batch_size=args.batch_size,
        normalize=True,
        local_files_only=True,
        target_dimension=args.embedding_dim,

        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —á–∞–Ω–∫–∏–Ω–≥–∞
        heading_aware=True,
        cohesion_aware=True,
        cohesion_split=True,
        chunk_target_tokens=args.chunk_size,
        chunk_max_tokens=512,
        chunk_min_tokens=64,
        min_chunk_tokens=64,
        overlap_sentences=1,
        sentence_overlap=1,
        table_as_is=True
    )

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±—ç–∫–µ–Ω–¥–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤...")
    emb = EmbeddingBackend(cfg)

    if emb.model is None:
        logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å SBERT!")
        sys.exit(1)
    else:
        logger.info(f"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞, —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {emb.dimension}")

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    if args.use_db:
        logger.info("–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö...")
        try:
            db = DB()
            db.ensure_schema()
            logger.info("–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {e}")
            sys.exit(1)
    else:
        logger.error(
            "–î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î (--use-db)")
        sys.exit(1)

    # –°–±–æ—Ä —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    logger.info(f"–ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ –≤ {input_dir}...")
    files = []
    for fmt in args.file_formats:
        pattern = f"**/*{fmt}"
        found = list(input_dir.glob(pattern))
        files.extend(found)
        logger.info(f"  –ù–∞–π–¥–µ–Ω–æ {len(found)} —Ñ–∞–π–ª–æ–≤ —Ñ–æ—Ä–º–∞—Ç–∞ {fmt}")

    files = sorted(set(files))

    if not files:
        logger.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤: {input_dir}")
        logger.warning(f"–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: {args.file_formats}")
        return 0

    logger.info(f"–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(files)}")

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    total_processed = 0
    total_classified = 0
    total_unclassified = 0
    classification_results = []

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞
    for file_idx, file_path in enumerate(files, 1):
        try:
            logger.info(
                f"[{file_idx}/{len(files)}] –û–±—Ä–∞–±–æ—Ç–∫–∞: {file_path.name}")

            # 1. –ü–∞—Ä—Å–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            logger.debug("  –ü–∞—Ä—Å–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞...")
            elements = parse_file_to_elements(
                str(file_path),
                category=str(file_path.parent.name)
            )

            if not elements:
                logger.warning(
                    f"  –î–æ–∫—É–º–µ–Ω—Ç –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å: {file_path.name}")
                continue

            logger.debug(f"  –ù–∞–π–¥–µ–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {len(elements)}")

            # 2. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞
            logger.debug(f"  –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞...")
            extracted_title = extract_title_universal(str(file_path))
            if extracted_title:
                logger.info(f"  –ò–∑–≤–ª–µ—á–µ–Ω–æ –Ω–∞–∑–≤–∞–Ω–∏–µ: '{extracted_title}'")
            else:
                logger.debug("  –ù–∞–∑–≤–∞–Ω–∏–µ –Ω–µ –∏–∑–≤–ª–µ—á–µ–Ω–æ")

            # 3. –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –≤—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            logger.debug("  –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞...")
            full_document_text = "\n".join(
                [el.text or "" for el in elements if el.text])

            if not full_document_text.strip():
                logger.warning(
                    f"  –î–æ–∫—É–º–µ–Ω—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞: {file_path.name}")
                continue

            document_embedding = emb.encode([full_document_text])[0]
            logger.debug(
                f"  –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {document_embedding.shape}")

            # 3.1. –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –Ω–∞–∑–≤–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞
            title_embedding = None
            if extracted_title and extracted_title.strip():
                logger.debug(f"  –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –Ω–∞–∑–≤–∞–Ω–∏—è...")
                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π (–µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π) –≤–µ–∫—Ç–æ—Ä
                title_embedding = emb.encode([extracted_title])[0]
                logger.debug(
                    f"  –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –Ω–∞–∑–≤–∞–Ω–∏—è: {title_embedding.shape}")
            else:
                logger.debug(
                    "  –≠–º–±–µ–¥–¥–∏–Ω–≥ –Ω–∞–∑–≤–∞–Ω–∏—è –Ω–µ —Å–æ–∑–¥–∞–Ω (–Ω–∞–∑–≤–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç)")

            # 4. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è - –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–µ–≥–æ —à–∞–±–ª–æ–Ω–∞
            logger.debug("  –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —à–∞–±–ª–æ–Ω–æ–≤...")
            similar_template_id, similarity_score, detailed_scores = classify_document(
                emb, db, full_document_text,
                title_text=extracted_title,
                document_weight=args.document_weight,
                title_weight=args.title_weight
            )

            if similar_template_id:
                logger.info(
                    f"  üü¢ –ù–ê–ô–î–ï–ù –ù–ê–ò–ë–û–õ–ï–ï –ü–û–•–û–ñ–ò–ô –®–ê–ë–õ–û–ù: –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–æ—Ö–æ–∂–µ—Å—Ç—å {similarity_score*100:.1f}% —Å —à–∞–±–ª–æ–Ω–æ–º {similar_template_id}")
                if detailed_scores:
                    logger.info(
                        f"     - –ü–æ—Ö–æ–∂–µ—Å—Ç—å –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç—É: {detailed_scores['doc_similarity']*100:.1f}%")
                    logger.info(
                        f"     - –ü–æ—Ö–æ–∂–µ—Å—Ç—å –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é: {detailed_scores['title_similarity']*100:.1f}%")

                # –°—á–∏—Ç–∞–µ–º –∫–∞–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π, –µ—Å–ª–∏ –ø–æ—Ö–æ–∂–µ—Å—Ç—å >= 50%
                if similarity_score >= 0.5:
                    total_classified += 1
                else:
                    total_unclassified += 1
            else:
                logger.info(
                    f"  üî¥ –ù–ï –ù–ê–ô–î–ï–ù –ü–û–î–•–û–î–Ø–©–ò–ô –®–ê–ë–õ–û–ù")
                total_unclassified += 1

            # 4. –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —á–∞–Ω–∫–∏–Ω–≥ (–∫–∞–∫ –≤ index_templates.py)
            logger.debug("  –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —á–∞–Ω–∫–∏–Ω–≥–∞...")
            chunks, stats = chunk_elements(
                elements,
                cfg=cfg,
                model=emb.model,
                tokenizer=None
            )

            if chunks:
                logger.debug(f"  –°–æ–∑–¥–∞–Ω–æ —á–∞–Ω–∫–æ–≤: {stats.total_chunks}")

                # –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è —á–∞–Ω–∫–æ–≤
                texts = [c["text"] for c in chunks]
                chunk_embeddings = emb.encode(texts)
                logger.debug(f"  –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ —á–∞–Ω–∫–æ–≤: {chunk_embeddings.shape}")
            else:
                logger.warning(
                    f"  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —á–∞–Ω–∫–∏ –¥–ª—è: {file_path.name}")
                chunks = []
                chunk_embeddings = np.zeros((0, args.embedding_dim))

            # 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
            try:
                doc_id = db.insert_incoming_document(
                    name=file_path.name,
                    version="",
                    file_path=str(file_path),
                    document_embedding=document_embedding,
                    similar_template_id=similar_template_id,
                    similarity_score=similarity_score,
                    session_id=args.session_id,
                    title=extracted_title,
                    title_embedding=title_embedding
                )

                if chunks:
                    db.insert_incoming_chunks(
                        doc_id,
                        [{
                            "text": c["text"],
                            "heading_path": c.get("heading_path", []),
                            "chunk_index": i
                        } for i, c in enumerate(chunks)],
                        chunk_embeddings
                    )

                logger.debug(f"  –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –ë–î: doc_id={doc_id}")
                if title_embedding is not None:
                    logger.debug(
                        f"    - –≠–º–±–µ–¥–¥–∏–Ω–≥ –Ω–∞–∑–≤–∞–Ω–∏—è: {title_embedding.shape}")
                if extracted_title:
                    logger.debug(f"    - –ù–∞–∑–≤–∞–Ω–∏–µ: '{extracted_title}'")
                logger.debug(f"    - –ß–∞–Ω–∫–æ–≤: {len(chunks)}")

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞
                classification_results.append({
                    "file_name": file_path.name,
                    "doc_id": doc_id,
                    "similar_template_id": similar_template_id,
                    "similarity_score": similarity_score,
                    "chunks_count": len(chunks),
                    "extracted_title": extracted_title,
                    "detailed_scores": detailed_scores
                })

            except Exception as e:
                logger.error(f"  –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î: {e}")
                # –ù–µ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º, –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –ë–î
                continue

            total_processed += 1

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ {file_path.name}: {e}")
            continue

    # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    logger.info("=" * 60)
    logger.info("–ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê")
    logger.info("=" * 60)
    logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {total_processed}")
    logger.info(f"–ù–∞–π–¥–µ–Ω–æ –ø–æ—Ö–æ–∂–∏—Ö —à–∞–±–ª–æ–Ω–æ–≤ (>=50%): {total_classified}")
    logger.info(f"–ù–∏–∑–∫–∞—è –ø–æ—Ö–æ–∂–µ—Å—Ç—å (<50%): {total_unclassified}")

    if total_processed > 0:
        success_rate = (total_classified / total_processed) * 100
        logger.info(
            f"–ü—Ä–æ—Ü–µ–Ω—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –≤—ã—Å–æ–∫–æ–π –ø–æ—Ö–æ–∂–µ—Å—Ç—å—é (>=50%): {success_rate:.1f}%")

    # –ü–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º
    if classification_results:
        logger.info("\n–î–ï–¢–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢:")
        logger.info("-" * 40)

        for result in classification_results:
            if result["similar_template_id"]:
                logger.info(f"üìÑ {result['file_name']}")
                if result.get("extracted_title"):
                    logger.info(f"   –ù–∞–∑–≤–∞–Ω–∏–µ: '{result['extracted_title']}'")
                logger.info(
                    f"   –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–æ—Ö–æ–∂–µ—Å—Ç—å: {result['similarity_score']*100:.1f}%")
                if result.get("detailed_scores"):
                    scores = result["detailed_scores"]
                    logger.info(
                        f"     ‚Ä¢ –ü–æ –¥–æ–∫—É–º–µ–Ω—Ç—É: {scores['doc_similarity']*100:.1f}%")
                    logger.info(
                        f"     ‚Ä¢ –ü–æ –Ω–∞–∑–≤–∞–Ω–∏—é: {scores['title_similarity']*100:.1f}%")
                logger.info(f"   –®–∞–±–ª–æ–Ω: {result['similar_template_id']}")
                logger.info(f"   –ß–∞–Ω–∫–æ–≤: {result['chunks_count']}")
            else:
                logger.info(f"üìÑ {result['file_name']} - –®–ê–ë–õ–û–ù –ù–ï –ù–ê–ô–î–ï–ù")
                if result.get("extracted_title"):
                    logger.info(f"   –ù–∞–∑–≤–∞–Ω–∏–µ: '{result['extracted_title']}'")
                    logger.info(f"   –ß–∞–Ω–∫–æ–≤: {result['chunks_count']}")

    # –ü–æ–ª—É—á–µ–Ω–∏–µ –∏ –≤—ã–≤–æ–¥ –æ–±—â–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑ –ë–î
    try:
        db_results = db.get_classification_results(limit=50)
        if db_results:
            logger.info(f"\n–ü–æ—Å–ª–µ–¥–Ω–∏–µ {len(db_results)} –∑–∞–ø–∏—Å–µ–π –≤ –ë–î:")
            logger.info("-" * 40)
            for result in db_results[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 10
                if result["similarity_score"]:
                    logger.info(
                        f"üìÑ {result['doc_name']} -> {result['template_name']} ({result['similarity_score']*100:.1f}%)")
                else:
                    logger.info(
                        f"üìÑ {result['doc_name']} -> –ù–ï –ö–õ–ê–°–°–ò–§–ò–¶–ò–†–û–í–ê–ù")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑ –ë–î: {e}")

    return 0


if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        logger.info("\n–ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(1)
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
        sys.exit(1)
